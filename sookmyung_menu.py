import requests
import csv
import json

# âœ… ì¹´ì¹´ì˜¤ API ì„¤ì •
API_KEY = "API KEY"
headers = {"Authorization": f"KakaoAK {API_KEY}"}

# ì²­íŒŒë™ ì¤‘ì‹¬ ì¢Œí‘œ
x, y = 126.96677012028513, 37.545067771838596
query = "ì‹ë‹¹"

# âœ… í‚¤ì›Œë“œ ê²€ìƒ‰ í•¨ìˆ˜
def search_keyword_places(query, x, y, radius=3000, page=1):
    url = "https://dapi.kakao.com/v2/local/search/keyword.json"
    params = {
        "query": query,
        "x": x,
        "y": y,
        "radius": radius,
        "page": page,
        "size": 15
    }
    res = requests.get(url, headers=headers, params=params)
    print(f"[DEBUG] Page {page} - status: {res.status_code}")
    try:
        return res.json()
    except Exception as e:
        print("[ERROR] JSON ë””ì½”ë”© ì‹¤íŒ¨:", e)
        return {}

def crawl_keyword_places(query, x, y, radius=3000, max_count=None):
    collected = []
    seen_ids = set()
    for page in range(1, 100): 
        result = search_keyword_places(query, x, y, radius, page)
        documents = result.get("documents", [])
        print(f"ğŸ“„ Page {page} - ìˆ˜ì‹ ëœ ê°€ê²Œ ìˆ˜: {len(documents)}")
        if not documents:
            break
        for place in documents:
            pid = place.get("id")
            if pid not in seen_ids:
                seen_ids.add(pid)
                collected.append(place)
    return collected


# âœ… CSV ì €ì¥
def save_to_csv(data, filename="ì²­íŒŒë™_ë§›ì§‘_50ê°œ.csv"):
    with open(filename, mode='w', newline='', encoding='utf-8') as file:
        writer = csv.writer(file)
        writer.writerow(["name", "address", "phone", "category", "lat", "lng", "id", "url"])
        for place in data:
            writer.writerow([
                place.get('place_name', ''),
                place.get('address_name', ''),
                place.get('phone', ''),
                place.get('category_name', ''),
                place.get('y', ''),
                place.get('x', ''),
                place.get('id', ''),
                place.get('place_url', '')
            ])

# âœ… JSON ì €ì¥
def save_to_json(data, filename="ì²­íŒŒë™_ë§›ì§‘_50ê°œ.json"):
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4)

# âœ… ì‹¤í–‰
if __name__ == "__main__":
    print(f"ğŸ” í‚¤ì›Œë“œ '{query}'ë¡œ ì²­íŒŒë™ ë§›ì§‘ 50ê°œ ìˆ˜ì§‘ ì¤‘...")
    places = crawl_keyword_places(query, x, y, radius=3000, max_count=50)
    print(f"ğŸ“¦ ì²­íŒŒë™ ë§›ì§‘ ìˆ˜ì§‘ ì™„ë£Œ: {len(places)}ê°œ")

    save_to_csv(places)
    save_to_json(places)
    print("âœ… ì €ì¥ ì™„ë£Œ! (CSV & JSON)")
